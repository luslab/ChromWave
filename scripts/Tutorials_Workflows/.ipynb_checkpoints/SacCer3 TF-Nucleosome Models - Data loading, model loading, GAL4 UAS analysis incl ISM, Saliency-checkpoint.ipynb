{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SacCer3 TF-nucleosome ChromWave\n",
    "\n",
    "In this notebook we show how to load and pre-processes sacCer3 MNase-seq data (Henikoff et al 2011) and trained ChromWave model. We compute in silico mutagenesis scores and saliency maps which we visualise using the DNA sequence of the GAL4 UAS as in Figure 2E."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import numpy\n",
    "import pandas\n",
    "import sys\n",
    "from chromwave import runtime_dataset, filesystem, chromwavenet, vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the directories\n",
    "\n",
    "You'll need the data in the repository, please make sure you've cloned it and the working directoy points to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# working directory should be ChromWave/scripts/Tutorials_Workflows. if not change project dir to be the directory \n",
    "# containing the code for ChromWave\n",
    "project_dir = os.path.abspath(os.path.join(os.getcwd(),'../../../'))\n",
    "working_dir = os.path.join(project_dir, 'ChromWave')\n",
    "working_dir = os.path.join(project_dir, 'ChromWave_python3')\n",
    "output_dir = os.path.join(project_dir,'Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join(working_dir, 'data')\n",
    "model_dir = os.path.join(working_dir, 'models')\n",
    "\n",
    "TF_profile1=os.path.join(data_dir,'henikoff2011','nuclei_20min_rep1_nucFree_fpm.bed')\n",
    "TF_profile2=os.path.join(data_dir,'henikoff2011','nuclei_20min_rep2_nucFree_fpm.bed')\n",
    "nuc_profile1=os.path.join(data_dir,'henikoff2011','nuclei_20min_rep1_monoNuc_fpm.bed')\n",
    "nuc_profile2=os.path.join(data_dir,'henikoff2011','nuclei_20min_rep2_monoNuc_fpm.bed')\n",
    "\n",
    "\n",
    "\n",
    "model_dir = os.path.join(model_dir,'tf-nucleosome/sacCer3')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/cakiroa/projects/ChromWave_python_3/data'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first set up the FileSystem, passing the location of the genome fa files, the output directory and nucleosome profiles of the in vitro profiles of the Kaplan et al 2009 data. If the output folder was already created wwe will overwrite as this instance. We have no test data to pass and we split the dataset into 20% test and 10% validation data (and 80% training data). \n",
    "\n",
    "We then load the data as a RuntimeDataset object with the underlying FileSystem. The sequences in the training, test and validation data will be shuffled but for testing purposes we use a fixed seed. We include the reverse complements of each sequence and remove sequences if a third of the region has a flat signal. The class weight cap denotes the max at which the class weights (computed as median/frequency per class) are capped to avoid extremely high weights for rarely occuring classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = [10, 5]\n",
    "source_profiles=[TF_profile1, nuc_profile1]\n",
    "tf_preprocessing_params = {'times_median_coverage_max': 3, 'u': u[0], 'smooth_signal': True,\n",
    "                            'sigma': 5, 'truncate': 3,\n",
    "                           'smoothing_function': 'gaussian_filter1d', \n",
    "                           'normalise_read_counts': 'genome_mean'}\n",
    "nuc_preprocessing_params = {'times_median_coverage_max': 3,'u': u[1], 'smooth_signal': True,\n",
    "                            'sigma': 5, 'truncate': 3,\n",
    "                            'smoothing_function': 'gaussian_filter1d',\n",
    "                            'normalise_read_counts': 'genome_mean'}\n",
    "preprocessing_params  = [tf_preprocessing_params,nuc_preprocessing_params]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": " FATAL ERROR: could not find source data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-395316167cc2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilesystem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFileSystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'genomes/sacCer3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Saliency'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_profile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msource_profiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresume\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mruntime_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRuntimeDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'raw_counts'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreprocessing_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfragment_length\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/ChromWave_python3/chromwave/filesystem.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, source_genome_data, output_path, source_profile, overwrite, resume, test_fraction, val_fraction)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_genome_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0msource_profile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresume\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_fraction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_fraction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_genome_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m' FATAL ERROR: could not find source data'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_source_data_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_genome_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m:  FATAL ERROR: could not find source data"
     ]
    }
   ],
   "source": [
    "f = filesystem.FileSystem(os.path.join(data_dir,'genomes/sacCer3'), os.path.join(output_dir,'Saliency'), source_profile=source_profiles, overwrite=True, resume=False)\n",
    "r = runtime_dataset.RuntimeDataset(f)\n",
    "r.data_format='raw_counts'\n",
    "r.preprocessing_params=preprocessing_params\n",
    "r.fragment_length =5000\n",
    "r.load_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by loading the in vivo and in vitro nucleosome models from the model directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TFNUC_model =  chromwavenet.ChromWaveNet()\n",
    "TFNUC_model.deserialize(directory = model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following plots the model architecture to the model directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "TFNUC_model.plot_model(directory=model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAL 4 UAS analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first select the region of interest (e.g. GAL4 UAS, see Figure 2E) and extract the genomic sequence (padded to 4000bp):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prom_chr='chrII'\n",
    "UAS_start = 278352\n",
    "UAS_end = 279021\n",
    "prom_start=UAS_start -500\n",
    "prom_end=5000+prom_start\n",
    "x=r.genome_data[r.chr_info.index(prom_chr)][:,prom_start:prom_end]\n",
    "x=numpy.expand_dims(numpy.swapaxes(x,0,1),0)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the predictions of ChromWave on the UAS site. To predict we are using the ChromWave function `predict_smooth` to postprocess the predicted classes into smoothed binding profiles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothed_predictions_UAS = TFNUC_model.predict_smooth(x)\n",
    "# To save as it's a list of lenght 2 with one prediction for each profile, you need to save with numpy.savez: \n",
    "#numpy.savez( os.path.join(directory,'Prediction_TF_NUC.npz'), *smoothed_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the predictions 500bp up- to 1000bp downstream ofthe start of the UAS site: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas.DataFrame(numpy.vstack(smoothed_predictions_UAS)[:,:1500].transpose(), columns=['TF pred', 'NUC pred']).plot(subplots=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the data +/- 500bp around the start of the UAS site to compare with the predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles=[r.profile_data_smooth[i][r.chr_info.index(prom_chr)][prom_start:(prom_start+1500)] for i in range(len(r.profile_data_smooth))]\n",
    "pandas.DataFrame(numpy.vstack(profiles).transpose(), columns=['TF', 'NUC']).plot(subplots=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In silico mutagenesis scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then use the functions of the ChromWave models to compute the in silico mutagenesis scores - we have 2 output profiles and `x_mut` is a list with 2 elements (which themselves are lists storing the differences in predicitons in the first entry). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mut = TFNUC_model.in_silico_mutagenesis(x,r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mut[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mut[1][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function returns a list of arrays: the difference in predictions between base change and WT, the predictions for each base change, the preactivations for each base change, and the difference of preactivations for each base change and WT. For sample 0, first base, the predictions of all possible basechanges in the TF profile are held in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mut[0][0][0,0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_mut_TF = x_mut[0][0]\n",
    "predictions_mut_NUC = x_mut[1][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ISM scores for a specific segment of the sequence is then computed as sum along axis 2 within the range we are interested in - here we do it along the whole sequence of the UAS site. The output array is of shape `[1,len_seq,num_bases]` and can be visualised as a heatmap downstream. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UAS_len = UAS_end - UAS_start\n",
    "min=500\n",
    "max=(500+UAS_len)\n",
    "# sum of delta within region min:max achievable by each base mutation\n",
    "sumdelta_per_base_mut_TF = numpy.sum(predictions_mut_TF[:,:,min:max,:],2)\n",
    "sumdelta_per_base_mut_NUC = numpy.sum(predictions_mut_NUC[:,:,min:max,:],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(40,20))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.imshow(numpy.squeeze(sumdelta_per_base_mut_TF,0)[min:max,:].transpose(), cmap='hot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(20,10))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.imshow(numpy.squeeze(sumdelta_per_base_mut_NUC,0)[min:max,:].transpose(), cmap='hot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the maximal gain and losses in the profile at each position given all possible base changes along the sequence to identify dynamic nucleosome binding 'hotspots' we can do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max achievable changes mutating the each base\n",
    "maxdelta_profile=numpy.max(numpy.max(predictions_mut_NUC,axis=1),-1)\n",
    "# min achievable changes mutating the each base\n",
    "mindelta_profile=numpy.min(numpy.min(predictions_mut_NUC,axis=1),-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas.DataFrame(numpy.vstack([maxdelta_profile,mindelta_profile]).transpose(), columns=['gain','loss']).plot(subplots=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saliency maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ChromWave models can compute the saliency maps for each output profile for certain positions (or ranges). Note that the function `compute_saliency` returns a list of arrays, so to save with numpy use `numpy.savez` as indicated below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saliency scores for the UAS site: padded from left by 500bp\n",
    "UAS_len = UAS_end - UAS_start\n",
    "min=500\n",
    "max=(500+UAS_len)\n",
    "saliceny_scores_for_seq = TFNUC_model.compute_saliency(sequence_data = x,min=min,max=max)\n",
    "# \n",
    "#numpy.savez( os.path.join(directory,Promoter_name+'scores.npz'), *scores_for_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 2 saliency maps for each of the profiles is held as list in `saliency_scores_for_seq`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas.DataFrame(numpy.stack([numpy.squeeze(numpy.sum(s,-1),0) for s in saliceny_scores_for_seq]).transpose(),columns=['saliency scores TF', 'saliency scores NUC']).plot(figsize=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chromwave.vis import viz_sequence\n",
    "viz_sequence.plot_weights(saliceny_scores_for_seq[0][:, (min+200):(min+600), :], subticks_frequency=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_sequence.plot_weights(saliceny_scores_for_seq[1][:, (min+200):(min+600), :], subticks_frequency=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cutting out the RSC-binding site"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The RSC motif is within the UAS site across the 273-333 basepairs. Here, as we have padded the UAS site with 500bp from left, we delete the base positions (500+273)-(500+334) to include bp 500+333. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_noRSC=numpy.delete(x, slice(500+272, 500+ 334), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before we can compute the predictions across this truncated sequence and plot the result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothed_predictions_UAS_noRSC=TFNUC_model.predict_smooth(x_noRSC) # predict returns the one-hot encoded signal\n",
    "pandas.DataFrame(numpy.vstack(smoothed_predictions_UAS_noRSC)[:,:1500].transpose(), columns=['TF pred', 'NUC pred']).plot(subplots=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cutting out the GAL4 binding site"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 3 GAL4 motifs in the 57 bp upstream of the previously cutout region - cutting these 57bp now.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_noGAL4=numpy.delete(x, slice(500+272-57, 500+272 +1), axis=1)\n",
    "smoothed_predictions_UAS_noGAL4=TFNUC_model.predict_smooth(x_noGAL4) # predict returns the one-hot encoded signal\n",
    "pandas.DataFrame(numpy.vstack(smoothed_predictions_UAS_noGAL4)[:,:1500].transpose(), columns=['TF pred', 'NUC pred']).plot(subplots=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
