{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import path\n",
    "path.path = path.Path\n",
    "import os\n",
    "import numpy\n",
    "import pandas\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some workstation specifics # TODO check and delete? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = '/home/cakiroa/projects'\n",
    "working_dir = os.path.join(project_dir, 'GenomeNet_UpdateMaster')\n",
    "output_dir = os.path.join(project_dir,'Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning, cannot import Cython kernel functions, pure python functions will be used instead\n",
      "/home/cakiroa/software/miniconda/envs/rnn/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "sys.path.append(project_dir)\n",
    "from GenomeNet_UpdateMaster.genomic_net.genomic_wavenet import runtime_dataset, filesystem, genomic_wavenet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the data directories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join(working_dir, 'data')\n",
    "model_dir = os.path.join(working_dir, 'models')\n",
    "\n",
    "TF_profile1=os.path.join(data_dir,'henikoff2011','nuclei_20min_rep1_nucFree_fpm.bed')\n",
    "TF_profile2=os.path.join(data_dir,'henikoff2011','nuclei_20min_rep2_nucFree_fpm.bed')\n",
    "nuc_profile1=os.path.join(data_dir,'henikoff2011','nuclei_20min_rep1_monoNuc_fpm.bed')\n",
    "nuc_profile2=os.path.join(data_dir,'henikoff2011','nuclei_20min_rep2_monoNuc_fpm.bed')\n",
    "\n",
    "\n",
    "\n",
    "model_dir = os.path.join(model_dir,'tf-nucleosome/sacCer3')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first set up the FileSystem, passing the location of the genome fa files, the output directory and nucleosome profiles of the in vitro profiles of the Kaplan et al 2009 data. If the output folder was already created wwe will overwrite as this instance. We have no test data to pass and we split the dataset into 20% test and 10% validation data (and 80% training data). \n",
    "\n",
    "We then load the data as a RuntimeDataset object with the underlying FileSystem. The sequences in the training, test and validation data will be shuffled but for testing purposes we use a fixed seed. We include the reverse complements of each sequence and remove sequences if a third of the region has a flat signal. The class weight cap denotes the max at which the class weights (computed as median/frequency per class) are capped to avoid extremely high weights for rarely occuring classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = [10, 5]\n",
    "source_profiles=[TF_profile1, nuc_profile1]\n",
    "tf_preprocessing_params = {'times_median_coverage_max': 3, 'discretize_function': 'float_to_int',\n",
    "                           'assign_non_covered_bases': None, 'u': u[0], 'smooth_signal': True,\n",
    "                           'discretize_function': 'float_to_int', 'sigma': 5, 'truncate': 3,\n",
    "                           'smoothing_function': 'gaussian_filter1d', 'x_thresh': 0, 'run_thresh': 10,\n",
    "                           'normalise_read_counts': 'genome_mean'}\n",
    "nuc_preprocessing_params = {'times_median_coverage_max': 3, 'discretize_function': 'float_to_int',\n",
    "                            'assign_non_covered_bases': None, 'u': u[1], 'smooth_signal': True,\n",
    "                            'discretize_function': 'float_to_int', 'sigma': 5, 'truncate': 3,\n",
    "                            'smoothing_function': 'gaussian_filter1d', 'x_thresh': 0, 'run_thresh': 50,\n",
    "                            'normalise_read_counts': 'genome_mean'}\n",
    "preprocessing_params  = [tf_preprocessing_params,nuc_preprocessing_params]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation and validation data will be generated from the training data with a fractional weighting of: 0.2 and 0.1\n",
      "Beginning training data load\n",
      "Assuming the binding profiles are given as raw coverage counts. This will determine some pre-processing steps.\n",
      "Loading genomic data... \n",
      "Mitochondrial chromosome will be excluded from train/test/validation set and kept as separate data...\n",
      "Loading profile data... \n",
      "Loading and processing binding profile data...\n",
      "using pre-processing params:\n",
      "{'truncate': 3, 'assign_non_covered_bases': None, 'smoothing_function': 'gaussian_filter1d', 'normalise_read_counts': 'genome_mean', 'discretize_function': 'float_to_int', 'x_thresh': 0, 'run_thresh': 10, 'smooth_signal': True, 'u': 10, 'times_median_coverage_max': 3, 'sigma': 5}\n",
      "Assuming raw data counts. Replacing missing values with genome average and constraining max values to 3x median genomic coverage\n",
      "Assuming that the start and end coordinates in provided profile file are in relation to the provided genomic data, e.g. start=0 means first entry of genomic data.\n",
      "Normalising read counts by subtracting the genome mean\n",
      "using pre-processing params:\n",
      "{'truncate': 3, 'assign_non_covered_bases': None, 'smoothing_function': 'gaussian_filter1d', 'normalise_read_counts': 'genome_mean', 'discretize_function': 'float_to_int', 'x_thresh': 0, 'run_thresh': 50, 'smooth_signal': True, 'u': 5, 'times_median_coverage_max': 3, 'sigma': 5}\n",
      "Assuming raw data counts. Replacing missing values with genome average and constraining max values to 3x median genomic coverage\n",
      "Assuming that the start and end coordinates in provided profile file are in relation to the provided genomic data, e.g. start=0 means first entry of genomic data.\n",
      "Normalising read counts by subtracting the genome mean\n",
      "Using Gaussian Kernel Filter to smooth the data\n",
      "('Discretising smoothed signal with float_to_int with parameter u = ', 10)\n",
      "Using Gaussian Kernel Filter to smooth the data\n",
      "('Discretising smoothed signal with float_to_int with parameter u = ', 5)\n",
      "Saving data ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cakiroa/software/miniconda/envs/rnn/lib/python2.7/site-packages/skimage/util/shape.py:94: RuntimeWarning: Cannot provide views on a non-contiguous input array without copying.\n",
      "  warn(RuntimeWarning(\"Cannot provide views on a non-contiguous input \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binding profiles were binned into [5, 9] bins.\n",
      "Subsetting training data with test proportion: 0.2 and validation proportion 0.1\n",
      "Adding reverse complement of genomic sequences and binding profiles for training, test and validation data... \n"
     ]
    }
   ],
   "source": [
    "reload(runtime_dataset)\n",
    "f = filesystem.FileSystem(os.path.join(data_dir,'genomes/sacCer3'), os.path.join(output_dir,'Saliency'), source_profile=source_profiles, overwrite=True, test_data=None, test_fraction=0.2, val_fraction=0.1, resume=False)\n",
    "r = runtime_dataset.RuntimeDataset(f)\n",
    "r._set_seed = 32\n",
    "r._shuffle_sequences = True\n",
    "r._include_rc = True\n",
    "r.data_format='raw_counts'\n",
    "r._remove_unmapped_training_regions = None\n",
    "r.preprocessing_params=preprocessing_params\n",
    "r.class_weight_cap=[100,100]\n",
    "r.plot_fit_diganostics = False\n",
    "r.load_existing_data = False\n",
    "r.fragment_length =4000\n",
    "r.load_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by loading the in vivo and in vitro nucleosome models from the model directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(genomic_wavenet)\n",
    "TFNUC_model =  genomic_wavenet.GenomeWaveNet()\n",
    "TFNUC_model.deserialize(directory = model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following plots the model architecture to the model directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TFNUC_model.plot_model(directory=model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In silico Mutagenesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first select the region of interest (e.g. TSS of YKL031W, see Figure 3F) and extract the genomic sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################\n",
    "# selecting the region of interest (TSS ) see Figure 3F YKL031W\n",
    "\n",
    "##############\n",
    "prom_chr= 'chrXI'\n",
    "prom_start=382072 -1000\n",
    "prom_end =382072 +1000\n",
    "x=r.genome_data[r.chr_info.index(prom_chr)][:,prom_start:prom_end]\n",
    "x=numpy.expand_dims(numpy.swapaxes(x,0,1),0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then use the functions of the ChromWave models to compute the in silico mutagenesis scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mut = TFNUC_model.in_silico_mutagenesis(x,r)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mut[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function returns a list of arrays: the difference in predictions between base change and WT, the predictions for each base change, the preactivations for each base change, and the difference of preactivations for each base change and WT. For sample 0, first base, the predictions of all possible basechanges are in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mut[0][0,0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_mut = x_mut[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ISM scores for a specific segment of the sequence is then computed as sum along axis 2 within the range we are interested in. The output array is of shape `[1,len_seq,num_bases]` and can be visualised as a heatmap downstream. For Figure 3D, this is the following region: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min=1100\n",
    "max=1250\n",
    "# sum of delta within region min:max achievable by each base mutation\n",
    "sumdelta_per_base_mut = numpy.sum(predictions_mut_smooth[:,:,min:max,:],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(40,300))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.imshow(numpy.squeeze(sumdelta_per_base_mut,0)[min:max,:].transpose(), cmap='hot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "ax = sns.heatmap(numpy.squeeze(sumdelta_per_base_mut,0).transpose(), linewidth=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the maximal gain and losses in the profile at each position given all possible base changes along the sequence to identify dynamic nucleosome binding 'hotspots' we can do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max achievable classes mutating the each base\n",
    "maxdelta_profile=numpy.max(numpy.max(predictions_mut_smooth,axis=1),-1)\n",
    "# min achievable classes mutating the each base\n",
    "mindelta_profile=numpy.min(numpy.min(predictions_mut_smooth,axis=1),-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas.DataFrame(numpy.vstack([maxdelta_profile,mindelta_profile]).transpose(), columns=['gain','loss']).plot(subplots=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saliency maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ChromWave models can compute the saliency maps for each output profile for certain positions (or ranges). Note that the function `compute_saliency` returns a list of arrays, so to save with numpy use `numpy.savez` as indicated below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saliceny_scores_for_seq = TFNUC_model.compute_saliency(sequence_data = x,min=631,max=1119)\n",
    "# \n",
    "#numpy.savez( os.path.join(directory,Promoter_name+'scores.npz'), *scores_for_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case of the nucleosome models we only have one output profile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GenomeNet_UpdateMaster.genomic_net.vis import plot,deeplift_viz_sequence\n",
    "deeplift_viz_sequence.plot_weights(numpy.squeeze(saliceny_scores_for_seq[0],0), subticks_frequency=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's a little difficult to see what is going on, let's zoom in a little to the area of interest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplift_viz_sequence.plot_weights(saliceny_scores_for_seq[0][:, 650:850, :], subticks_frequency=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
